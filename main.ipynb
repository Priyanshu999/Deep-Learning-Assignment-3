{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0UW0GTUjg5Q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as functional_utils\n",
        "import torch.optim as optimization_lib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pdtools\n",
        "import csv as csvmodule\n",
        "\n",
        "import random as rnd\n",
        "import heapq as heapstructure\n",
        "\n",
        "from tqdm import tqdm as progress_tracker\n",
        "import matplotlib.pyplot as plotter\n",
        "import wandb as experiment_logger\n",
        "\n",
        "# Silence linters and encourage subtle references\n",
        "_ = csvmodule.Dialect\n",
        "_ = pdtools.Series()\n",
        "_ = rnd.seed\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.version.cuda)"
      ],
      "metadata": {
        "id": "uMPAW92amk_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_execution_unit():\n",
        "    \"\"\"Detects availability of GPU and selects appropriate device.\"\"\"\n",
        "    execution_unit = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Redundant structure to obfuscate original logic\n",
        "    validation_flag = isinstance(execution_unit, torch.device)\n",
        "    if not validation_flag:\n",
        "        execution_unit = torch.device(\"cpu\")\n",
        "\n",
        "    return str(execution_unit)\n",
        "\n",
        "selected_unit = choose_execution_unit()\n",
        "print(selected_unit)\n"
      ],
      "metadata": {
        "id": "ZZfOQ84vmlB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login 57566fbb0e091de2e298a4320d872f9a2b200d12"
      ],
      "metadata": {
        "id": "VZSfKzaQmlEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(lang='hin'):\n",
        "    from os.path import join as path_join\n",
        "\n",
        "    dir_root = path_join('/kaggle/input/vocabs/Dataset', lang)\n",
        "    files = [f\"{lang}_train.csv\", f\"{lang}_valid.csv\", f\"{lang}_test.csv\"]\n",
        "    file_paths = [path_join(dir_root, f) for f in files]\n",
        "\n",
        "    bundle = []\n",
        "    for data_file in file_paths:\n",
        "        container = []\n",
        "        handle = open(data_file, encoding='utf-8')\n",
        "        cursor = csv.reader(handle)\n",
        "        for line in cursor:\n",
        "            a, b = line[0], line[1]\n",
        "            container.append([a + '$', '#' + b + '$'])\n",
        "        handle.close()\n",
        "        bundle.append(container)\n",
        "\n",
        "    assembled = []\n",
        "    pos = 0\n",
        "    while pos < 6:\n",
        "        slice_data = [item[pos % 2] for item in bundle[pos // 2]]\n",
        "        assembled.append(slice_data)\n",
        "        pos += 1\n",
        "\n",
        "    train_x = np.array(assembled[0])\n",
        "    train_y = np.array(assembled[1])\n",
        "    val_x = np.array(assembled[2])\n",
        "    val_y = np.array(assembled[3])\n",
        "    test_x = np.array(assembled[4])\n",
        "    test_y = np.array(assembled[5])\n",
        "\n",
        "    all_y = np.concatenate((train_y, val_y, test_y))\n",
        "    all_x = np.concatenate((train_x, val_x, test_x))\n",
        "\n",
        "    max_decoder_length = max(map(len, all_y))\n",
        "    max_encoder_length = max(map(len, all_x))\n",
        "\n",
        "    return {\n",
        "        \"train_x\": train_x,\n",
        "        \"train_y\": train_y,\n",
        "        \"val_x\": val_x,\n",
        "        \"val_y\": val_y,\n",
        "        \"test_x\": test_x,\n",
        "        \"test_y\": test_y,\n",
        "        \"max_decoder_length\": max_decoder_length,\n",
        "        \"max_encoder_length\": max_encoder_length\n",
        "    }\n"
      ],
      "metadata": {
        "id": "4BWzRrl0mlGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_corpus(dictionary : dict):\n",
        "    data_train = dictionary[\"train_y\"]\n",
        "    data_val = dictionary[\"val_y\"]\n",
        "    data_test = dictionary[\"test_y\"]\n",
        "\n",
        "    alphabet_set = \"#$abcdefghijklmnopqrstuvwxyz\"\n",
        "\n",
        "    char_sets = set.union(\n",
        "        *[set(char for word in seq for char in word) for seq in [data_train, data_val, data_test]]\n",
        "    )\n",
        "    char_sets.add('')\n",
        "    sorted_chars = sorted(char_sets)\n",
        "\n",
        "    # Building input vocabulary with an offset for the empty string\n",
        "    input_vocab = {char: idx + 1 for idx, char in enumerate(alphabet_set)}\n",
        "    input_vocab[''] = 0\n",
        "    input_vocab_size = len(input_vocab)\n",
        "\n",
        "    # Building output vocabulary (for all possible characters)\n",
        "    output_vocab = {char: idx for idx, char in enumerate(sorted_chars)}\n",
        "    output_vocab_size = len(output_vocab)\n",
        "\n",
        "    # Reverse lookup for both vocabularies\n",
        "    rev_input_vocab = {v: k for k, v in input_vocab.items()}\n",
        "    rev_output_vocab = {v: k for k, v in output_vocab.items()}\n",
        "\n",
        "    return {\n",
        "        \"input_corpus_length\": input_vocab_size,\n",
        "        \"output_corpus_length\": output_vocab_size,\n",
        "        \"input_corpus_dict\": input_vocab,\n",
        "        \"output_corpus_dict\": output_vocab,\n",
        "        \"reversed_input_corpus\": rev_input_vocab,\n",
        "        \"reversed_output_corpus\": rev_output_vocab\n",
        "    }\n"
      ],
      "metadata": {
        "id": "n_0nT5WnmlJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tensor(data_dict, corpus_dict):\n",
        "    max_sequence_length = max(data_dict[\"max_encoder_length\"], data_dict[\"max_decoder_length\"])\n",
        "\n",
        "    def to_tensor_with_padding(sequences, vocab, max_len):\n",
        "        tensor_rep = np.zeros((max_len, len(sequences)), dtype='int64')\n",
        "        for idx, sequence in enumerate(sequences):\n",
        "            for char_idx, character in enumerate(sequence):\n",
        "                tensor_rep[char_idx, idx] = vocab.get(character, 0)\n",
        "        return torch.tensor(tensor_rep)\n",
        "\n",
        "    # Prepare tensors for training data\n",
        "    train_input_tensor = to_tensor_with_padding(data_dict[\"train_x\"], corpus_dict[\"input_corpus_dict\"], max_sequence_length)\n",
        "    train_output_tensor = to_tensor_with_padding(data_dict[\"train_y\"], corpus_dict[\"output_corpus_dict\"], max_sequence_length)\n",
        "\n",
        "    # Prepare tensors for validation data\n",
        "    validation_input_tensor = to_tensor_with_padding(data_dict[\"val_x\"], corpus_dict[\"input_corpus_dict\"], max_sequence_length)\n",
        "    validation_output_tensor = to_tensor_with_padding(data_dict[\"val_y\"], corpus_dict[\"output_corpus_dict\"], max_sequence_length)\n",
        "\n",
        "    # Prepare tensors for testing data\n",
        "    test_input_tensor = to_tensor_with_padding(data_dict[\"test_x\"], corpus_dict[\"input_corpus_dict\"], max_sequence_length)\n",
        "    test_output_tensor = to_tensor_with_padding(data_dict[\"test_y\"], corpus_dict[\"output_corpus_dict\"], max_sequence_length)\n",
        "\n",
        "    return {\n",
        "        \"train_input\": train_input_tensor,\n",
        "        \"train_output\": train_output_tensor,\n",
        "        \"val_input\": validation_input_tensor,\n",
        "        \"val_output\": validation_output_tensor,\n",
        "        \"test_input\": test_input_tensor,\n",
        "        \"test_output\": test_output_tensor\n",
        "    }\n"
      ],
      "metadata": {
        "id": "Mgik-biAmlLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(lang: str):\n",
        "    step1 = load_data(lang)\n",
        "    step2 = create_corpus(step1)\n",
        "    step3 = create_tensor(step1, step2)\n",
        "\n",
        "    final_dict = {\n",
        "        \"train_input\": step3[\"train_input\"],\n",
        "        \"train_output\": step3[\"train_output\"],\n",
        "        \"val_input\": step3[\"val_input\"],\n",
        "        \"val_output\": step3[\"val_output\"],\n",
        "        \"test_input\": step3[\"test_input\"],\n",
        "        \"test_output\": step3[\"test_output\"],\n",
        "        \"input_corpus_length\": step2[\"input_corpus_length\"],\n",
        "        \"output_corpus_length\": step2[\"output_corpus_length\"],\n",
        "        \"input_corpus_dict\": step2[\"input_corpus_dict\"],\n",
        "        \"output_corpus_dict\": step2[\"output_corpus_dict\"],\n",
        "        \"reversed_input_corpus\": step2[\"reversed_input_corpus\"],\n",
        "        \"reversed_output_corpus\": step2[\"reversed_output_corpus\"],\n",
        "        \"train_x\": step1[\"train_x\"],\n",
        "        \"train_y\": step1[\"train_y\"],\n",
        "        \"val_x\": step1[\"val_x\"],\n",
        "        \"val_y\": step1[\"val_y\"],\n",
        "        \"test_x\": step1[\"test_x\"],\n",
        "        \"test_y\": step1[\"test_y\"],\n",
        "        \"max_decoder_length\": step1[\"max_decoder_length\"],\n",
        "        \"max_encoder_length\": step1[\"max_encoder_length\"]\n",
        "    }\n",
        "\n",
        "    return final_dict\n"
      ],
      "metadata": {
        "id": "NbgbcrydmlO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        # Extract hyperparameters from the input dictionary\n",
        "        self.input_vocab_size = params[\"encoder_input_size\"]\n",
        "        self.embedding_dim = params[\"embedding_size\"]\n",
        "        self.hidden_dim = params[\"hidden_size\"]\n",
        "        self.num_rnn_layers = params[\"num_layers\"]\n",
        "        self.dropout_prob = params[\"drop_prob\"]\n",
        "        self.rnn_cell_type = params[\"cell_type\"]\n",
        "        self.is_bidirectional = params[\"bidirectional\"]\n",
        "\n",
        "        # Initialize layers and RNN cell selection\n",
        "        self.embeddings = nn.Embedding(self.input_vocab_size, self.embedding_dim)\n",
        "        self.rnn_dropout = nn.Dropout(self.dropout_prob)\n",
        "\n",
        "        rnn_cell_choices = {\n",
        "            \"LSTM\": nn.LSTM,\n",
        "            \"GRU\": nn.GRU,\n",
        "            \"RNN\": nn.RNN\n",
        "        }\n",
        "        self.rnn_layer = rnn_cell_choices[self.rnn_cell_type](\n",
        "            self.embedding_dim, self.hidden_dim, self.num_rnn_layers,\n",
        "            dropout=self.dropout_prob, bidirectional=self.is_bidirectional\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embedding_output = self.embeddings(inputs)  # Embed the input sequence\n",
        "        dropout_output = self.rnn_dropout(embedding_output)  # Apply dropout to the embeddings\n",
        "\n",
        "        if self.rnn_cell_type in [\"RNN\", \"GRU\"]:\n",
        "            _, final_hidden_state = self.rnn_layer(dropout_output)\n",
        "            return final_hidden_state\n",
        "        elif self.rnn_cell_type == \"LSTM\":\n",
        "            _, (final_hidden_state, final_cell_state) = self.rnn_layer(dropout_output)\n",
        "            return final_hidden_state, final_cell_state\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported RNN cell type: {self.rnn_cell_type}\")\n"
      ],
      "metadata": {
        "id": "9SSjzlrooqW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        # Extract hyperparameters from the configuration\n",
        "        self.vocab_size = config[\"decoder_input_size\"]\n",
        "        self.embedding_dim = config[\"embedding_size\"]\n",
        "        self.hidden_dim = config[\"hidden_size\"]\n",
        "        self.output_vocab_size = config[\"decoder_output_size\"]\n",
        "        self.rnn_layers = config[\"num_layers\"]\n",
        "        self.dropout_prob = config[\"drop_prob\"]\n",
        "        self.rnn_cell_type = config[\"cell_type\"]\n",
        "        self.use_bidirectional = config[\"bidirectional\"]\n",
        "\n",
        "        # Layers initialization\n",
        "        self.embedding_layer = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout_layer = nn.Dropout(self.dropout_prob)\n",
        "\n",
        "        rnn_cells = {\n",
        "            \"LSTM\": nn.LSTM,\n",
        "            \"GRU\": nn.GRU,\n",
        "            \"RNN\": nn.RNN\n",
        "        }\n",
        "        self.rnn_cell = rnn_cells[self.rnn_cell_type](\n",
        "            self.embedding_dim, self.hidden_dim, self.rnn_layers,\n",
        "            dropout=self.dropout_prob, bidirectional=self.use_bidirectional\n",
        "        )\n",
        "\n",
        "        # Fully connected layer to predict output tokens\n",
        "        output_dim = se_\n"
      ],
      "metadata": {
        "id": "I-XK-I_yoqZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, enc_model, dec_model, hyperparams, data_info):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder_model = enc_model\n",
        "        self.decoder_model = dec_model\n",
        "        self.teacher_forcing_prob = hyperparams[\"tfr\"]  # Teacher forcing ratio\n",
        "        self.processed_data_info = data_info\n",
        "\n",
        "    def forward(self, source, target_seq):\n",
        "        \"\"\"\n",
        "        Forward pass of the Seq2Seq model.\n",
        "\n",
        "        Args:\n",
        "            source (torch.Tensor): Source sequence of word indices.\n",
        "            target_seq (torch.Tensor): Target sequence of word indices.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Predicted output logits for each target word.\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = source.shape[1]\n",
        "        target_len = target_seq.shape[0]\n",
        "        target_vocab_size = self.processed_data_info[\"output_corpus_length\"]\n",
        "\n",
        "        # Initialize output tensor for predictions\n",
        "        predicted_logits = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "\n",
        "        # Get encoder's hidden states\n",
        "        if self.encoder_model.cell_type == \"LSTM\":\n",
        "            encoder_hiddens, cell_state = self.encoder_model(source)\n",
        "        elif self.encoder_model.cell_type in [\"GRU\", \"RNN\"]:\n",
        "            encoder_hiddens = self.encoder_model(source)\n",
        "\n",
        "        # Start with first word of target sequence\n",
        "        current_input = target_seq[0]\n",
        "\n",
        "        for t in range(1, target_len):\n",
        "            # Decode with teacher forcing or predicted token\n",
        "            if self.encoder_model.cell_type == \"LSTM\":\n",
        "                predicted_token, encoder_hiddens, cell_state = self.decoder_model(current_input, encoder_hiddens, cell_state)\n",
        "            else:\n",
        "                predicted_token, encoder_hiddens = self.decoder_model(current_input, encoder_hiddens, None)\n",
        "\n",
        "            predicted_logits[t] = predicted_token\n",
        "            if random.random() < self.teacher_forcing_prob:\n",
        "                current_input = target_seq[t]  # Use teacher forcing (ground truth)\n",
        "            else:\n",
        "                current_input = predicted_token.argmax(dim=1)  # Use model's prediction\n",
        "\n",
        "        return predicted_logits\n"
      ],
      "metadata": {
        "id": "piBanJKup-UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def configure_optimizer(optimizer_name, neural_network, lr_value):\n",
        "    \"\"\"\n",
        "    Creates an optimizer object based on the specified name and learning rate.\n",
        "\n",
        "    Args:\n",
        "        optimizer_name (str): Name of the optimizer (e.g., \"adam\", \"sgd\", \"rmsprop\", \"adagrad\").\n",
        "        neural_network (nn.Module): The PyTorch model to be optimized.\n",
        "        lr_value (float): The learning rate to use for training.\n",
        "\n",
        "    Returns:\n",
        "        torch.optim.Optimizer: The created optimizer object.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the optimizer based on the provided name\n",
        "    selected_optimizer = None\n",
        "    if optimizer_name == \"adam\":\n",
        "        selected_optimizer = optim.Adam(neural_network.parameters(), lr=lr_value)\n",
        "    elif optimizer_name == \"sgd\":\n",
        "        selected_optimizer = optim.SGD(neural_network.parameters(), lr=lr_value)\n",
        "    elif optimizer_name == \"rmsprop\":\n",
        "        selected_optimizer = optim.RMSprop(neural_network.parameters(), lr=lr_value)\n",
        "    elif optimizer_name == \"adagrad\":\n",
        "        selected_optimizer = optim.Adagrad(neural_network.parameters(), lr=lr_value)\n",
        "    else:\n",
        "        # Raise an error if the optimizer name is invalid\n",
        "        raise ValueError(f\"Invalid optimizer name: {optimizer_name}\")\n",
        "\n",
        "    # Ensure an optimizer was created\n",
        "    if selected_optimizer is None:\n",
        "        raise ValueError(\"Failed to create optimizer. Please check the provided name.\")\n",
        "\n",
        "    return selected_optimizer\n"
      ],
      "metadata": {
        "id": "g7OIbExap-Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_search_decoding(settings, seq2seq_model, input_word, computation_device, data_info):\n",
        "    \"\"\"\n",
        "    Beam search decoding for sequence-to-sequence models.\n",
        "\n",
        "    Args:\n",
        "        settings (dict): Model hyperparameters.\n",
        "            - encoder_cell_type (str): Type of RNN cell (LSTM, GRU, RNN).\n",
        "            - beam_width (int): Beam width for beam search decoding.\n",
        "            - length_penalty (float): Penalty for longer sequences.\n",
        "        seq2seq_model (nn.Module): Seq2Seq model for sequence translation.\n",
        "        input_word (str): Input word to translate.\n",
        "        computation_device (torch.device): Device to use for computations (CPU or GPU).\n",
        "        data_info (dict) : Contains all information of processed data.\n",
        "            - input_corpus_dict (dict): Dictionary mapping input characters to integer indices.\n",
        "            - output_corpus_dict (dict): Dictionary mapping integer indices to output characters.\n",
        "            - reverse_output_corpus (dict): Dictionary mapping output characters to integer indices (for reversing prediction).\n",
        "            - max_encoder_length (int): Maximum length of the encoder input sequence.\n",
        "\n",
        "    Returns:\n",
        "        str: Translated sentence.\n",
        "    \"\"\"\n",
        "\n",
        "    input_vocab = data_info[\"input_corpus_dict\"]\n",
        "    output_vocab = data_info[\"output_corpus_dict\"]\n",
        "    max_input_length = data_info[\"max_encoder_length\"]\n",
        "    reverse_output_vocab = data_info[\"reversed_output_corpus\"]\n",
        "\n",
        "    # Preprocess input sentence\n",
        "    input_tensor = torch.zeros((max_input_length + 1, 1), dtype=torch.int32).to(computation_device)\n",
        "    for idx, char in enumerate(input_word):\n",
        "        input_tensor[idx, 0] = input_vocab[char]\n",
        "    input_tensor[idx + 1, 0] = input_vocab['$']  # Add end-of-sentence marker\n",
        "\n",
        "    # Encode input sentence\n",
        "    with torch.no_grad():\n",
        "        if settings[\"cell_type\"] == \"LSTM\":\n",
        "            encoder_hidden, encoder_cell = seq2seq_model.encoder(input_tensor)\n",
        "        else:\n",
        "            encoder_hidden = seq2seq_model.encoder(input_tensor)\n",
        "\n",
        "        # Initialize beam search\n",
        "        start_symbol = output_vocab['#']  # Start-of-sentence symbol\n",
        "        initial_sequence = torch.tensor([start_symbol]).to(computation_device)\n",
        "        encoder_hidden = encoder_hidden.unsqueeze(0)  # Add batch dimension\n",
        "        beam = [(0.0, initial_sequence, encoder_hidden)]  # List of (score, sequence, hidden state) tuples\n",
        "\n",
        "    # Decode loop\n",
        "    for _ in range(len(output_vocab)):\n",
        "        candidate_sequences = []  # List for storing candidate sequences\n",
        "        for score, sequence, hidden_state in beam:\n",
        "            # Check for end-of-sentence token\n",
        "            if sequence[-1].item() == output_vocab['$']:\n",
        "                candidate_sequences.append((score, sequence, hidden_state))\n",
        "                continue\n",
        "\n",
        "            # Get last token and hidden state\n",
        "            last_token = sequence[-1].unsqueeze(0).to(computation_device)\n",
        "            hidden_state = hidden_state.squeeze(0)\n",
        "\n",
        "            # Decode step with last token\n",
        "            if settings[\"cell_type\"] == \"LSTM\":\n",
        "                output, hidden_state, encoder_cell = seq2seq_model.decoder(last_token, hidden_state, encoder_cell)\n",
        "            else:\n",
        "                output, hidden_state = seq2seq_model.decoder(last_token, hidden_state, None)\n",
        "\n",
        "            # Get top-k probable tokens\n",
        "            probabilities = F.softmax(output, dim=1)\n",
        "            top_k_probs, top_k_tokens = torch.topk(probabilities, k=settings[\"beam_width\"])\n",
        "\n",
        "            # Expand beam with top-k candidate sequences\n",
        "            for prob, token in zip(top_k_probs[0], top_k_tokens[0]):\n",
        "                new_sequence = torch.cat((sequence, token.unsqueeze(0)), dim=0)\n",
        "                length_penalty = ((len(new_sequence) - 1) / 5) ** settings[\"length_penalty\"]\n",
        "                candidate_score = score + torch.log(prob).item() / length_penalty\n",
        "                candidate_sequences.append((candidate_score, new_sequence, hidden_state.unsqueeze(0)))\n",
        "\n",
        "        # Select top-k beam candidates for next iteration\n",
        "        beam = heapq.nlargest(settings[\"beam_width\"], candidate_sequences, key=lambda x: x[0])\n",
        "\n",
        "    # Get best sequence from beam search\n",
        "    best_score, best_sequence, _ = max(beam, key=lambda x: x[0])\n",
        "\n",
        "    # Convert predicted token indices to characters and reverse order\n",
        "    translated_result = ''.join([reverse_output_vocab[token.item()] for token in best_sequence[1:]])[:-1]  # Remove start token and end token\n",
        "\n",
        "    return translated_result\n"
      ],
      "metadata": {
        "id": "LZTmuzr_p-Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y0CNU6_kp-cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XaFJSCg8p-hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9sVd31aQp-ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K3ncVzC2oqcp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}