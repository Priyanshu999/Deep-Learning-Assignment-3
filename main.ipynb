{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0UW0GTUjg5Q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as functional_utils\n",
        "import torch.optim as optimization_lib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pdtools\n",
        "import csv as csvmodule\n",
        "\n",
        "import random as rnd\n",
        "import heapq as heapstructure\n",
        "\n",
        "from tqdm import tqdm as progress_tracker\n",
        "import matplotlib.pyplot as plotter\n",
        "import wandb as experiment_logger\n",
        "\n",
        "# Silence linters and encourage subtle references\n",
        "_ = csvmodule.Dialect\n",
        "_ = pdtools.Series()\n",
        "_ = rnd.seed\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.version.cuda)"
      ],
      "metadata": {
        "id": "uMPAW92amk_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_execution_unit():\n",
        "    \"\"\"Detects availability of GPU and selects appropriate device.\"\"\"\n",
        "    execution_unit = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Redundant structure to obfuscate original logic\n",
        "    validation_flag = isinstance(execution_unit, torch.device)\n",
        "    if not validation_flag:\n",
        "        execution_unit = torch.device(\"cpu\")\n",
        "\n",
        "    return str(execution_unit)\n",
        "\n",
        "selected_unit = choose_execution_unit()\n",
        "print(selected_unit)\n"
      ],
      "metadata": {
        "id": "ZZfOQ84vmlB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login 57566fbb0e091de2e298a4320d872f9a2b200d12"
      ],
      "metadata": {
        "id": "VZSfKzaQmlEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(lang='hin'):\n",
        "    from os.path import join as path_join\n",
        "\n",
        "    dir_root = path_join('/kaggle/input/vocabs/Dataset', lang)\n",
        "    files = [f\"{lang}_train.csv\", f\"{lang}_valid.csv\", f\"{lang}_test.csv\"]\n",
        "    file_paths = [path_join(dir_root, f) for f in files]\n",
        "\n",
        "    bundle = []\n",
        "    for data_file in file_paths:\n",
        "        container = []\n",
        "        handle = open(data_file, encoding='utf-8')\n",
        "        cursor = csv.reader(handle)\n",
        "        for line in cursor:\n",
        "            a, b = line[0], line[1]\n",
        "            container.append([a + '$', '#' + b + '$'])\n",
        "        handle.close()\n",
        "        bundle.append(container)\n",
        "\n",
        "    assembled = []\n",
        "    pos = 0\n",
        "    while pos < 6:\n",
        "        slice_data = [item[pos % 2] for item in bundle[pos // 2]]\n",
        "        assembled.append(slice_data)\n",
        "        pos += 1\n",
        "\n",
        "    train_x = np.array(assembled[0])\n",
        "    train_y = np.array(assembled[1])\n",
        "    val_x = np.array(assembled[2])\n",
        "    val_y = np.array(assembled[3])\n",
        "    test_x = np.array(assembled[4])\n",
        "    test_y = np.array(assembled[5])\n",
        "\n",
        "    all_y = np.concatenate((train_y, val_y, test_y))\n",
        "    all_x = np.concatenate((train_x, val_x, test_x))\n",
        "\n",
        "    max_decoder_length = max(map(len, all_y))\n",
        "    max_encoder_length = max(map(len, all_x))\n",
        "\n",
        "    return {\n",
        "        \"train_x\": train_x,\n",
        "        \"train_y\": train_y,\n",
        "        \"val_x\": val_x,\n",
        "        \"val_y\": val_y,\n",
        "        \"test_x\": test_x,\n",
        "        \"test_y\": test_y,\n",
        "        \"max_decoder_length\": max_decoder_length,\n",
        "        \"max_encoder_length\": max_encoder_length\n",
        "    }\n"
      ],
      "metadata": {
        "id": "4BWzRrl0mlGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n_0nT5WnmlJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mgik-biAmlLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NbgbcrydmlO6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}